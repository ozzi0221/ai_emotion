"""
í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°

íšŒìƒì¹˜ë£Œ AI ì•„ë°”íƒ€ì—ì„œ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê¸°ëŠ¥ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import re
import json
from typing import List, Dict, Optional, Tuple
from datetime import datetime

# í•œêµ­ì–´ íšŒìƒì¹˜ë£Œ ê´€ë ¨ í‚¤ì›Œë“œ ì‚¬ì „
MEMORY_KEYWORDS = {
    'ì‹œê°„ëŒ€': {
        'ì–´ë¦°ì‹œì ˆ': ['ì–´ë¦´ë•Œ', 'ì–´ë¦°ì‹œì ˆ', 'ì´ˆë“±í•™êµ', 'êµ­ë¯¼í•™êµ', 'ì–´ë ¸ì„ë•Œ', 'ê¼¬ë§ˆë•Œ', 'ì•„ì´ë•Œ'],
        'ì²­ì†Œë…„ê¸°': ['ì¤‘í•™êµ', 'ê³ ë“±í•™êµ', 'ì²­ì†Œë…„', '10ëŒ€', 'í•™ì°½ì‹œì ˆ', 'ìˆ˜í—˜ìƒ', 'ì…ì‹œ'],
        'ì²­ë…„ê¸°': ['ëŒ€í•™êµ', '20ëŒ€', 'ì Šì—ˆì„ë•Œ', 'ì‹ í˜¼', 'ê²°í˜¼', 'ì·¨ì—…', 'ì‚¬íšŒìƒí™œ'],
        'ì¥ë…„ê¸°': ['30ëŒ€', '40ëŒ€', 'ì¤‘ë…„', 'ì§ì¥ìƒí™œ', 'ìŠ¹ì§„', 'ì•„ì´ë“¤', 'ìœ¡ì•„'],
        'ë…¸ë…„ê¸°': ['50ëŒ€', '60ëŒ€', 'ì€í‡´', 'ì†ì', 'ì†ë…€', 'í‡´ì§', 'ë…¸í›„']
    },
    'ì¥ì†Œ': {
        'ê³ í–¥': ['ê³ í–¥', 'ì‹œê³¨', 'ë†ì´Œ', 'ë§ˆì„', 'ë™ë„¤', 'ìš°ë¦¬ì§‘', 'ì¹œì •', 'ì‹œëŒ'],
        'í•™êµ': ['í•™êµ', 'êµì‹¤', 'ìš´ë™ì¥', 'ë„ì„œê´€', 'ê°•ë‹¹', 'êµë¬´ì‹¤', 'í•™ì›'],
        'ì§ì¥': ['íšŒì‚¬', 'ì‚¬ë¬´ì‹¤', 'ê³µì¥', 'ê°€ê²Œ', 'ìƒì ', 'ì‚¬ì—…ì¥', 'ì¼í„°'],
        'ë†€ì´ì¥ì†Œ': ['ë†€ì´í„°', 'ê³µì›', 'ì‚°', 'ê°•', 'ë°”ë‹¤', 'ì‹œì¥', 'ê·¹ì¥', 'êµíšŒ']
    },
    'ì¸ë¬¼': {
        'ê°€ì¡±': ['ì–´ë¨¸ë‹ˆ', 'ì•„ë²„ì§€', 'ì—„ë§ˆ', 'ì•„ë¹ ', 'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'í˜•', 'ëˆ„ë‚˜', 'ì–¸ë‹ˆ', 'ë™ìƒ', 'ë‚¨í¸', 'ì•„ë‚´', 'ì•„ë“¤', 'ë”¸', 'ë©°ëŠë¦¬', 'ì‚¬ìœ„'],
        'ì¹œêµ¬': ['ì¹œêµ¬', 'ë™ì°½', 'ì„ ë°°', 'í›„ë°°', 'ë™ê¸°', 'ë™ë£Œ', 'ì´ì›ƒ', 'ì„ ìƒë‹˜'],
        'ì—°ì¸': ['ë‚¨ìì¹œêµ¬', 'ì—¬ìì¹œêµ¬', 'ì²«ì‚¬ë‘', 'ì• ì¸', 'ì—°ì¸', 'ì¢‹ì•„í•˜ë˜']
    },
    'í™œë™': {
        'ë†€ì´': ['ë†€ì´', 'ê²Œì„', 'ìˆ¨ë°”ê¼­ì§ˆ', 'ìˆ ë˜ì¡ê¸°', 'ê³µê¸°ë†€ì´', 'ë”±ì§€ì¹˜ê¸°', 'êµ¬ìŠ¬ì¹˜ê¸°'],
        'ìŒì‹': ['ë°¥', 'ë°˜ì°¬', 'ê¹€ì¹˜', 'ëœì¥ì°Œê°œ', 'ë¼ë©´', 'ê³¼ì', 'ë–¡', 'ì—¿', 'ì‚¬íƒ•'],
        'ìŒì•…': ['ë…¸ë˜', 'ìŒì•…', 'ê°€ìš”', 'íŠ¸ë¡œíŠ¸', 'ë™ìš”', 'ì°¬ì†¡ê°€', 'ë¯¼ìš”'],
        'ëª…ì ˆ': ['ì„¤ë‚ ', 'ì¶”ì„', 'ë‹¨ì˜¤', 'ì–´ë²„ì´ë‚ ', 'í¬ë¦¬ìŠ¤ë§ˆìŠ¤', 'ìƒì¼']
    }
}

# ê°ì • ê´€ë ¨ í‚¤ì›Œë“œ
EMOTION_KEYWORDS = {
    'ê¸ì •ì ': ['ê¸°ìœ', 'í–‰ë³µí•œ', 'ì¦ê±°ìš´', 'ì¬ë¯¸ìˆëŠ”', 'ì¢‹ì€', 'ë”°ëœ»í•œ', 'ì‚¬ë‘ìŠ¤ëŸ¬ìš´', 'ê³ ë§ˆìš´', 'ë¿Œë“¯í•œ'],
    'ê·¸ë¦¬ìš´': ['ê·¸ë¦¬ìš´', 'ë³´ê³ ì‹¶ì€', 'ê·¸ë•Œê°€', 'ì•„ì‰¬ìš´', 'ì• í‹‹í•œ', 'ê°„ì ˆí•œ'],
    'í˜ë“ ': ['í˜ë“ ', 'ì–´ë ¤ìš´', 'ìŠ¬í”ˆ', 'ì•„í”ˆ', 'ê³ ìƒ', 'ê³ ë‹¬í”ˆ', 'ê´´ë¡œìš´'],
    'í‰ì˜¨í•œ': ['í‰ì˜¨í•œ', 'ì¡°ìš©í•œ', 'ì°¨ë¶„í•œ', 'í¸ì•ˆí•œ', 'ì•ˆë½í•œ', 'ê³ ìš”í•œ']
}

# ìœ íŠœë¸Œ ê²€ìƒ‰ í‚¤ì›Œë“œ ë§¤í•‘
YOUTUBE_SEARCH_MAPPING = {
    'ìŒì•…': {
        'ê³ í–¥ì˜ë´„': 'ê³ í–¥ì˜ ë´„ ë…¸ë˜ ì´ì€í•˜',
        'ê°œì—¬ìš¸': 'ì •ë¯¸ì¡° ê°œì—¬ìš¸',
        'ë´‰ì„ í™”': 'ë´‰ì„ í™” ì—°ì • ì´ë¯¸ì',
        'ì• ìˆ˜': 'ì• ìˆ˜ ì´ë¯¸ì',
        'ê·¸ëŒ€ì™€ ì˜ì›íˆ': 'ê·¸ëŒ€ì™€ ì˜ì›íˆ ì–‘í¬ì€',
        'ìƒë¡ìˆ˜': 'ìƒë¡ìˆ˜ í˜„ì¸',
        'ëª©í¬ì˜ ëˆˆë¬¼': 'ëª©í¬ì˜ ëˆˆë¬¼ ì´ë‚œì˜'
    },
    'ì˜ìƒ': {
        '60ë…„ëŒ€': '1960ë…„ëŒ€ í•œêµ­ ì˜›ë‚  ì˜ìƒ',
        '70ë…„ëŒ€': '1970ë…„ëŒ€ í•œêµ­ ì˜›ë‚  ì‚¬ì§„',
        '80ë…„ëŒ€': '1980ë…„ëŒ€ ì¶”ì–µ ì˜ìƒ',
        'ì‹œê³¨': 'ì˜›ë‚  ì‹œê³¨ ë§ˆì„ í’ê²½',
        'í•™êµ': 'ì˜›ë‚  í•™êµ êµì‹¤ ì¶”ì–µ'
    }
}

def extract_memory_keywords(text: str) -> Dict[str, List[str]]:
    """í…ìŠ¤íŠ¸ì—ì„œ íšŒìƒì¹˜ë£Œ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    found_keywords = {}
    
    for category, subcategories in MEMORY_KEYWORDS.items():
        for subcategory, keywords in subcategories.items():
            found_words = []
            for keyword in keywords:
                if keyword in text:
                    found_words.append(keyword)
            
            if found_words:
                if category not in found_keywords:
                    found_keywords[category] = {}
                found_keywords[category][subcategory] = found_words
    
    return found_keywords

def extract_emotions(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ê°ì • í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    emotions = []
    
    for emotion_type, keywords in EMOTION_KEYWORDS.items():
        for keyword in keywords:
            if keyword in text:
                emotions.append(emotion_type)
                break
    
    return emotions

def extract_youtube_search_terms(text: str) -> List[str]:
    """í…ìŠ¤íŠ¸ì—ì„œ ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    search_terms = []
    
    # ì§ì ‘ì ì¸ ë…¸ë˜ ì œëª© ì–¸ê¸‰
    for song_key, search_term in YOUTUBE_SEARCH_MAPPING['ìŒì•…'].items():
        if song_key in text:
            search_terms.append(search_term)
    
    # ì‹œëŒ€ì  ë°°ê²½ ì–¸ê¸‰
    for era_key, search_term in YOUTUBE_SEARCH_MAPPING['ì˜ìƒ'].items():
        if era_key in text:
            search_terms.append(search_term)
    
    # íŒ¨í„´ ê¸°ë°˜ ì¶”ì¶œ
    patterns = [
        r'(?:ë…¸ë˜|ìŒì•…|ê³¡).*?[\'\"](.*?)[\'\"]*?(?:ë“¤ë ¤|í‹€ì–´|ì°¾ì•„)',
        r'[\'\"](.*?)[\'\"]*?(?:ë…¸ë˜|ìŒì•…|ê³¡)',
        r'(?:ìœ íŠœë¸Œì—ì„œ|ê²€ìƒ‰í•´).*?[\'\"](.*?)[\'\"]*',
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        for match in matches:
            if match.strip():
                search_terms.append(match.strip() + ' ë…¸ë˜')
    
    return list(set(search_terms))  # ì¤‘ë³µ ì œê±°

def clean_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
    # íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì¼ë¶€ ìœ ì§€)
    text = re.sub(r'[^\w\sê°€-í£.,!?~â™ªâ™«ğŸµğŸ˜ŠğŸ˜„ğŸ˜¢ğŸ’â¤ï¸ğŸ ğŸ¼]', '', text)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    
    # ì•ë’¤ ê³µë°± ì œê±°
    text = text.strip()
    
    return text

def is_appropriate_content(text: str) -> bool:
    """íšŒìƒì¹˜ë£Œì— ì ì ˆí•œ ë‚´ìš©ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    inappropriate_keywords = [
        'ì •ì¹˜', 'ì¢…êµ', 'ëˆ', 'ë³‘', 'ì£½ìŒ', 'ì‚¬ê³ ', 'ì „ìŸ', 'í­ë ¥', 'ìš•ì„¤'
    ]
    
    text_lower = text.lower()
    for keyword in inappropriate_keywords:
        if keyword in text_lower:
            return False
    
    return True

def suggest_follow_up_questions(memory_keywords: Dict, emotions: List[str]) -> List[str]:
    """ì¶”ì¶œëœ í‚¤ì›Œë“œì™€ ê°ì •ì„ ë°”íƒ•ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•©ë‹ˆë‹¤."""
    questions = []
    
    # ì‹œê°„ëŒ€ ê¸°ë°˜ ì§ˆë¬¸
    if 'ì‹œê°„ëŒ€' in memory_keywords:
        for period in memory_keywords['ì‹œê°„ëŒ€'].keys():
            if period == 'ì–´ë¦°ì‹œì ˆ':
                questions.append("ê·¸ë•Œ ì§‘ ì•ì€ ì–´ë–¤ ëª¨ìŠµì´ì—ˆë‚˜ìš”?")
                questions.append("ì–´ë¦´ ë•Œ ê°€ì¥ ì¢‹ì•„í–ˆë˜ ë†€ì´ê°€ ìˆìœ¼ì…¨ë‚˜ìš”?")
            elif period == 'ì²­ë…„ê¸°':
                questions.append("ì²« ì§ì¥ì€ ì–´ë– ì…¨ë‚˜ìš”?")
                questions.append("ê·¸ë•Œ ì¢‹ì•„í•˜ë˜ ë…¸ë˜ê°€ ìˆìœ¼ì…¨ë‚˜ìš”?")
    
    # ì¥ì†Œ ê¸°ë°˜ ì§ˆë¬¸
    if 'ì¥ì†Œ' in memory_keywords:
        if 'ê³ í–¥' in memory_keywords['ì¥ì†Œ']:
            questions.append("ê³ í–¥ì—ì„œ ê°€ì¥ ê¸°ì–µì— ë‚¨ëŠ” ê³³ì€ ì–´ë””ì¸ê°€ìš”?")
        if 'í•™êµ' in memory_keywords['ì¥ì†Œ']:
            questions.append("í•™ì°½ì‹œì ˆ ê°€ì¥ ì¬ë¯¸ìˆì—ˆë˜ ì¶”ì–µì´ ìˆìœ¼ì‹ ê°€ìš”?")
    
    # ê°ì • ê¸°ë°˜ ì§ˆë¬¸
    if 'ê¸ì •ì ' in emotions:
        questions.append("ê·¸ë•Œ ì •ë§ í–‰ë³µí•˜ì…¨ê² ì–´ìš”. ë˜ ë‹¤ë¥¸ ì¢‹ì€ ê¸°ì–µì€ ì—†ìœ¼ì‹ ê°€ìš”?")
    if 'ê·¸ë¦¬ìš´' in emotions:
        questions.append("ì •ë§ ê·¸ë¦¬ìš°ì…¨ê² ì–´ìš”. ê·¸ë¶„ë“¤ê³¼ì˜ ì¶”ì–µì„ ë” ë“¤ë ¤ì£¼ì„¸ìš”.")
    
    return questions[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ ë°˜í™˜

def format_response_with_emotions(text: str, emotions: List[str]) -> str:
    """ê°ì •ì— ë§ëŠ” ì´ëª¨ì§€ì™€ í‘œí˜„ì„ ì¶”ê°€í•©ë‹ˆë‹¤."""
    if 'ê¸ì •ì ' in emotions:
        text += " ğŸ˜Š"
    elif 'ê·¸ë¦¬ìš´' in emotions:
        text += " ğŸ’"
    elif 'í˜ë“ ' in emotions:
        text += " ë”°ëœ»í•˜ê²Œ ì•ˆì•„ë“œë¦¬ê³  ì‹¶ì–´ìš”."
    elif 'í‰ì˜¨í•œ' in emotions:
        text += " ğŸŒ¸"
    
    return text

def create_conversation_summary(conversations: List[Dict]) -> Dict:
    """ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½í•©ë‹ˆë‹¤."""
    if not conversations:
        return {}
    
    total_keywords = {}
    total_emotions = []
    topics = set()
    
    for conv in conversations:
        text = conv.get('user', '') + ' ' + conv.get('assistant', '')
        
        # í‚¤ì›Œë“œ ì§‘ê³„
        keywords = extract_memory_keywords(text)
        for category, subcategories in keywords.items():
            if category not in total_keywords:
                total_keywords[category] = {}
            for subcategory, words in subcategories.items():
                if subcategory not in total_keywords[category]:
                    total_keywords[category][subcategory] = []
                total_keywords[category][subcategory].extend(words)
        
        # ê°ì • ì§‘ê³„
        emotions = extract_emotions(text)
        total_emotions.extend(emotions)
        
        # ì£¼ì œ ì¶”ì¶œ
        for category in keywords.keys():
            topics.add(category)
    
    return {
        'keywords': total_keywords,
        'emotions': list(set(total_emotions)),
        'topics': list(topics),
        'conversation_count': len(conversations),
        'summary_date': datetime.now().isoformat()
    }

def generate_personalized_greeting(user_history: Dict) -> str:
    """ì‚¬ìš©ì íˆìŠ¤í† ë¦¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ì¸ì‚¬ë§ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not user_history:
        return "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ì¶”ì–µì„ ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹œë‚˜ìš”? ğŸ˜Š"
    
    topics = user_history.get('topics', [])
    emotions = user_history.get('emotions', [])
    
    if 'ì‹œê°„ëŒ€' in topics:
        return "ì•ˆë…•í•˜ì„¸ìš”! ì§€ë‚œë²ˆì— ë§ì”€í•´ì£¼ì‹  ì¶”ì–µì´ ì •ë§ ì¸ìƒê¹Šì—ˆì–´ìš”. ì˜¤ëŠ˜ì€ ë˜ ì–´ë–¤ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì‹¤ê¹Œìš”? ğŸ˜Š"
    elif 'ê¸ì •ì ' in emotions:
        return "ì•ˆë…•í•˜ì„¸ìš”! ì§€ë‚œë²ˆ í–‰ë³µí•œ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì…”ì„œ ì €ë„ ê¸°ë»¤ì–´ìš”. ì˜¤ëŠ˜ë„ ì¢‹ì€ ì¶”ì–µ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”? ğŸ’"
    else:
        return "ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ì†Œì¤‘í•œ ì¶”ì–µì„ í•¨ê»˜ ë‚˜ëˆ„ê³  ì‹¶ìœ¼ì‹œë‚˜ìš”? ğŸ˜Š"

# í…ìŠ¤íŠ¸ ê²€ì¦ í•¨ìˆ˜ë“¤
def validate_user_input(text: str) -> Tuple[bool, str]:
    """ì‚¬ìš©ì ì…ë ¥ì„ ê²€ì¦í•©ë‹ˆë‹¤."""
    if not text or not text.strip():
        return False, "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
    
    if len(text) > 500:
        return False, "ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 500ì ì´ë‚´ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”."
    
    if not is_appropriate_content(text):
        return False, "íšŒìƒì¹˜ë£Œì— ì í•©í•˜ì§€ ì•Šì€ ë‚´ìš©ì…ë‹ˆë‹¤. ë‹¤ë¥¸ ì£¼ì œë¡œ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”?"
    
    return True, ""

# ì˜ˆì‹œ ì‚¬ìš©ë²•
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_text = "ì–´ë¦´ ë•Œ ê³ í–¥ì—ì„œ ì–´ë¨¸ë‹ˆì™€ í•¨ê»˜ ê³ í–¥ì˜ ë´„ ë…¸ë˜ë¥¼ ë“¤ì—ˆì–´ìš”. ì •ë§ ê·¸ë¦¬ìš´ ì¶”ì–µì´ì—ìš”."
    
    print("=== í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ ===")
    print(f"ì›ë³¸ í…ìŠ¤íŠ¸: {test_text}")
    print(f"ë©”ëª¨ë¦¬ í‚¤ì›Œë“œ: {extract_memory_keywords(test_text)}")
    print(f"ê°ì •: {extract_emotions(test_text)}")
    print(f"ìœ íŠœë¸Œ ê²€ìƒ‰ì–´: {extract_youtube_search_terms(test_text)}")
    print(f"í›„ì† ì§ˆë¬¸: {suggest_follow_up_questions(extract_memory_keywords(test_text), extract_emotions(test_text))}")
