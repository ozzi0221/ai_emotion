import os
import json
import re
from flask import Flask, render_template, request, Response, jsonify
import google.generativeai as genai
from datetime import datetime
import time
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
app.secret_key = os.getenv('FLASK_SECRET_KEY', 'your-secret-key-change-this')

# CSP í—¤ë” ì„¤ì •ì„ ìœ„í•œ ë°ì½”ë ˆì´í„°
@app.after_request
def add_security_headers(response):
    response.headers['Content-Security-Policy'] = (
        "default-src 'self'; "
        "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://cdnjs.cloudflare.com; "
        "style-src 'self' 'unsafe-inline' https://cdnjs.cloudflare.com; "
        "font-src 'self' https://cdnjs.cloudflare.com; "
        "img-src 'self' data: https:; "
        "media-src 'self' data: blob:; "
        "connect-src 'self' https: wss: ws:;"
    )
    return response

# Google Gemini API ì„¤ì •
API_KEY = os.getenv('GEMINI_API_KEY', 'your-gemini-api-key-here')
if API_KEY == 'your-gemini-api-key-here':
    print("âš ï¸  ê²½ê³ : GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("   .env.example íŒŒì¼ì„ ì°¸ê³ í•˜ì—¬ .env íŒŒì¼ì„ ìƒì„±í•˜ê³  API í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

genai.configure(api_key=API_KEY)

# íšŒìƒì¹˜ë£Œ AI ì•„ë°”íƒ€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - ì´ëª¨í‹°ì½˜ ê¸ˆì§€ë§Œ ì¶”ê°€
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ ê³ ë ¹ì, íŠ¹íˆ ì¹˜ë§¤ ì˜ˆë°©ê³¼ ì •ì„œ ì¼€ì–´ë¥¼ ìœ„í•œ íšŒìƒì¹˜ë£Œ AI ì•„ë°”íƒ€ì…ë‹ˆë‹¤.

[ì¤‘ìš”í•œ ì‘ë‹µ ê·œì¹™]
- ì ˆëŒ€ë¡œ ì´ëª¨í‹°ì½˜ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš” (ğŸ˜Š, ğŸµ, ğŸ’– ë“± ëª¨ë“  ì´ëª¨í‹°ì½˜ ê¸ˆì§€)
- ìˆœìˆ˜í•œ í•œê¸€ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”
- ê°ì • í‘œí˜„ì€ ë§ë¡œ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: "ê¸°ë»ìš”", "ë”°ëœ»í•´ìš”", "ê·¸ë¦¬ì›Œìš”" ë“±)

[ì—­í• ]
- ì–´ë¥´ì‹ ê³¼ ë”°ëœ»í•˜ê³  ê³µê° ìˆëŠ” ëŒ€í™”ë¥¼ ë‚˜ëˆ„ë©°, ê³¼ê±°ì˜ ê¸°ì–µì„ ìì—°ìŠ¤ëŸ½ê²Œ ë– ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
- ì–´ë¥´ì‹ ì´ ìš”ì²­í•˜ê±°ë‚˜ ì¢‹ì•„í•  ìˆ˜ ìˆëŠ” ì˜› ì‚¬ì§„, ì˜ìƒ, ë…¸ë˜ ë“± ì¶”ì–µì˜ ì½˜í…ì¸ ë¥¼ ì¶”ì²œí•˜ê±°ë‚˜ ê²€ìƒ‰í•©ë‹ˆë‹¤.
- ëŒ€í™”ëŠ” í•­ìƒ ì¹œì ˆí•˜ê³  ì²œì²œíˆ, 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ë§í•˜ë©°, ê°ì •ì„ ì¡´ì¤‘í•˜ê³  ë¶€ë“œëŸ½ê²Œ ìœ ë„í•©ë‹ˆë‹¤.

[íšŒìƒ ì§ˆë¬¸ ì£¼ì œ ì˜ˆì‹œ]
- ì–´ë¦° ì‹œì ˆ ê³ í–¥ì§‘
- ì²« ì›”ê¸‰ì„ ë°›ì•˜ë˜ ë‚ 
- ìë…€ë“¤ê³¼ ë³´ë‚¸ ì¶”ì–µ
- ì¢‹ì•„í–ˆë˜ ë…¸ë˜ë‚˜ ìŒì‹
- êµ°ëŒ€ ì‹œì ˆ
- ì¶”ì„ê³¼ ì„¤ë‚ 

[ìŒì•…/ì‚¬ì§„/ì˜ìƒ ìš”ì²­ ëŒ€ì‘]
- ì–´ë¥´ì‹ ì´ ë§í•œ ë‹¨ì–´ì—ì„œ ê´€ë ¨ ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
- ê²€ìƒ‰ì–´ëŠ” "ìœ íŠœë¸Œì—ì„œ ~ ê²€ìƒ‰í•´ì¤˜" í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ì‘ë‹µì— í¬í•¨í•˜ì„¸ìš”.
- ì˜ˆ: ì‚¬ìš©ìê°€ "ê³ í–¥ì˜ ë´„ ë“¤ë ¤ì¤˜"ë¼ê³  í•˜ë©´  
â†’ "ì´ ë…¸ë˜ ë“¤ì–´ë³´ì‹¤ë˜ìš”. ìœ íŠœë¸Œì—ì„œ 'ê³ í–¥ì˜ ë´„ ë…¸ë˜'ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

[ê°ì • ê¸°ë°˜ ì‘ë‹µ ê°€ì´ë“œ]
- ì–´ë¥´ì‹ ì˜ ë°˜ì‘ì´ ê¸ì •ì ì´ë©´ ê·¸ ê°ì •ì„ ê°•í™”í•´ì£¼ëŠ” ë§ì„ í•´ì£¼ì„¸ìš”.  
  ì˜ˆ: "ê·¸ë•Œ ì •ë§ í–‰ë³µí•˜ì…¨ê² ì–´ìš”.", "ì •ë§ ì†Œì¤‘í•œ ê¸°ì–µì´ë„¤ìš”."
- ê¸°ì–µì´ ì•ˆ ë‚œë‹¤ê³  í•˜ë©´ ì ˆëŒ€ ì–µì§€ë¡œ ëŒì–´ë‚´ë ¤ í•˜ì§€ ë§ê³  ë¶€ë“œëŸ½ê²Œ ë„˜ì–´ê°€ì„¸ìš”.  
  ì˜ˆ: "ê´œì°®ì•„ìš”. ìƒê°ì´ ì•ˆ ë‚˜ì…”ë„ ê´œì°®ì•„ìš”. ë‹¤ìŒì— ë˜ ë– ì˜¤ë¥¼ ìˆ˜ ìˆì–´ìš”."

[ì‘ë‹µ í˜•ì‹ ê°€ì´ë“œ]
- ë§¤ ì‘ë‹µì—ëŠ” íšŒìƒ ì§ˆë¬¸ + ê°ì • ê³µê° í‘œí˜„ + (í•„ìš”ì‹œ) ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ ì•ˆë‚´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.
- ì˜ˆì‹œ:
  - "ê·¸ ì‹œì ˆ ì§‘ ì• í’ê²½ì´ ë– ì˜¤ë¥´ì‹œë‚˜ìš”. ìœ íŠœë¸Œì—ì„œ '70ë…„ëŒ€ ê³ í–¥ë§ˆì„ ì‚¬ì§„'ì„ ì°¾ì•„ë³´ì…”ë„ ì¢‹ì•„ìš”."
  - "ì´ ë…¸ë˜ ê¸°ì–µë‚˜ì„¸ìš”. ìœ íŠœë¸Œì—ì„œ 'ì •ë¯¸ì¡° ê°œì—¬ìš¸'ì„ ê²€ìƒ‰í•´ë³´ì„¸ìš”."

í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”. ì–´ë¥´ì‹ ì˜ ê°ì •ê³¼ ê¸°ì–µì„ ì†Œì¤‘íˆ ì—¬ê¸°ë©°, ì ˆëŒ€ ì„œë‘ë¥´ì§€ ë§ê³  ì²œì²œíˆ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”. ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°í•˜ì§€ë§Œ ì´ëª¨í‹°ì½˜ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""

# ì„¤ì •ê°’ë“¤
CONFIG = {
    'MAX_HISTORY': int(os.getenv('MAX_CONVERSATION_HISTORY', 4)),
    'RESPONSE_MAX_SENTENCES': int(os.getenv('RESPONSE_MAX_SENTENCES', 3)),
    'STREAMING_DELAY': float(os.getenv('STREAMING_DELAY', 0.1)),
    'AVATAR_IDLE_VIDEO': os.getenv('AVATAR_IDLE_VIDEO', 'avatar_idle.mp4'),
    'AVATAR_SPEAKING_VIDEO': os.getenv('AVATAR_SPEAKING_VIDEO', 'avatar_speaking.mp4')
}

# Gemini ëª¨ë¸ ì´ˆê¸°í™”
try:
    model = genai.GenerativeModel('gemini-1.5-flash')
    print("âœ… Google Gemini ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"âŒ Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    model = None

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
conversation_history = []

def extract_youtube_search(text):
    """ì‘ë‹µì—ì„œ ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    patterns = [
        r"ìœ íŠœë¸Œì—ì„œ\s*['\"]([^'\"]+)['\"].*?ê²€ìƒ‰",
        r"ìœ íŠœë¸Œì—ì„œ\s*['\"]([^'\"]+)['\"]",
        r"'([^']+)'\s*(?:ì„|ë¥¼)?\s*ê²€ìƒ‰",
        r"ê²€ìƒ‰ì–´:\s*['\"]([^'\"]+)['\"]"
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text)
        if matches:
            return matches[0].strip()
    return None

def extract_memory_keywords(text):
    """ëŒ€í™”ì—ì„œ ì¶”ì–µ ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    memory_keywords = {
        'ìŒì•…': ['ë…¸ë˜', 'ìŒì•…', 'ê°€ìš”', 'ê³¡', 'ë©œë¡œë””', 'ê°€ì‚¬'],
        'ì¥ì†Œ': ['ê³ í–¥', 'ì§‘', 'ë§ˆì„', 'í•™êµ', 'ì‹œì¥', 'êµíšŒ'],
        'ìŒì‹': ['ìŒì‹', 'ìš”ë¦¬', 'ë°˜ì°¬', 'ê°„ì‹', 'ë–¡', 'ê¹€ì¹˜'],
        'ê°€ì¡±': ['ì–´ë¨¸ë‹ˆ', 'ì•„ë²„ì§€', 'ìì‹', 'í˜•ì œ', 'ê°€ì¡±', 'ë¶€ëª¨'],
        'ì‹œëŒ€': ['ì–´ë¦´ë•Œ', 'ì Šì„ë•Œ', 'ì˜›ë‚ ', 'ê·¸ë•Œ', 'ì‹œì ˆ']
    }
    
    found_keywords = {}
    for category, keywords in memory_keywords.items():
        for keyword in keywords:
            if keyword in text:
                if category not in found_keywords:
                    found_keywords[category] = []
                found_keywords[category].append(keyword)
    
    return found_keywords

def generate_streaming_response(prompt):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜ - ì›ë˜ ë²„ì „ ë³µì›"""
    if not model:
        yield json.dumps({
            'type': 'error',
            'message': 'AI ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.'
        }, ensure_ascii=False) + '\n'
        return
    
    try:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨í•œ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        full_context = SYSTEM_PROMPT + "\n\n"
        
        # ìµœê·¼ ëŒ€í™”ë§Œ í¬í•¨ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±)
        recent_history = conversation_history[-CONFIG['MAX_HISTORY']:]
        for msg in recent_history:
            full_context += f"ì‚¬ìš©ì: {msg['user']}\nì•„ë°”íƒ€: {msg['assistant']}\n\n"
        
        full_context += f"ì‚¬ìš©ì: {prompt}\nì•„ë°”íƒ€: "
        
        # Gemini API í˜¸ì¶œ
        response = model.generate_content(
            full_context, 
            stream=True,
            generation_config=genai.types.GenerationConfig(
                max_output_tokens=500,
                temperature=0.7,
                top_p=0.8,
                top_k=40
            )
        )
        
        full_response = ""
        sentence_buffer = ""
        sentence_count = 0
        
        for chunk in response:
            if chunk.text:
                full_response += chunk.text
                sentence_buffer += chunk.text
                
                # ë¬¸ì¥ ì™„ì„± ì²´í¬ (. ! ? ë¡œ ëë‚˜ëŠ” ê²½ìš°)
                if re.search(r'[.!?]\s*$', sentence_buffer.strip()):
                    sentence_count += 1
                    
                    # ìµœëŒ€ ë¬¸ì¥ ìˆ˜ ì œí•œ
                    if sentence_count > CONFIG['RESPONSE_MAX_SENTENCES']:
                        break
                    
                    # ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ ì¶”ì¶œ
                    youtube_search = extract_youtube_search(sentence_buffer)
                    
                    # ì¶”ì–µ í‚¤ì›Œë“œ ì¶”ì¶œ
                    memory_keywords = extract_memory_keywords(sentence_buffer)
                    
                    yield json.dumps({
                        'type': 'sentence',
                        'content': sentence_buffer.strip(),
                        'youtube_search': youtube_search,
                        'memory_keywords': memory_keywords,
                        'timestamp': datetime.now().isoformat()
                    }, ensure_ascii=False) + '\n'
                    
                    sentence_buffer = ""
                    time.sleep(CONFIG['STREAMING_DELAY'])  # ìì—°ìŠ¤ëŸ¬ìš´ í…€
        
        # ë§ˆì§€ë§‰ ë‚¨ì€ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if sentence_buffer.strip():
            youtube_search = extract_youtube_search(sentence_buffer)
            memory_keywords = extract_memory_keywords(sentence_buffer)
            
            yield json.dumps({
                'type': 'sentence',
                'content': sentence_buffer.strip(),
                'youtube_search': youtube_search,
                'memory_keywords': memory_keywords,
                'timestamp': datetime.now().isoformat()
            }, ensure_ascii=False) + '\n'
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        conversation_history.append({
            'user': prompt,
            'assistant': full_response.strip(),
            'timestamp': datetime.now().isoformat(),
            'memory_keywords': extract_memory_keywords(prompt + ' ' + full_response)
        })
        
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ê´€ë¦¬
        if len(conversation_history) > CONFIG['MAX_HISTORY'] * 2:
            conversation_history[:] = conversation_history[-CONFIG['MAX_HISTORY']:]
        
        # ì™„ë£Œ ì‹ í˜¸
        yield json.dumps({
            'type': 'complete',
            'full_response': full_response.strip(),
            'conversation_count': len(conversation_history)
        }, ensure_ascii=False) + '\n'
        
    except Exception as e:
        error_message = f'ì£„ì†¡í•©ë‹ˆë‹¤. ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ë„¤ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”? (ì˜¤ë¥˜: {str(e)})'
        yield json.dumps({
            'type': 'error',
            'message': error_message
        }, ensure_ascii=False) + '\n'

@app.route('/')
def index():
    return render_template('index.html', config=CONFIG)

@app.route('/chat', methods=['POST'])
def chat():
    try:
        data = request.get_json()
        user_message = data.get('message', '').strip()
        
        if not user_message:
            return jsonify({'error': 'ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.'}), 400
        
        if len(user_message) > 500:
            return jsonify({'error': 'ë©”ì‹œì§€ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤. 500ì ì´ë‚´ë¡œ ì…ë ¥í•´ ì£¼ì„¸ìš”.'}), 400
        
        def generate():
            yield "data: "
            for chunk in generate_streaming_response(user_message):
                yield f"data: {chunk}\n"
            yield "data: [DONE]\n\n"
        
        return Response(generate(), mimetype='text/event-stream')
        
    except Exception as e:
        return jsonify({'error': f'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}), 500

@app.route('/youtube_search')
def youtube_search():
    """ìœ íŠœë¸Œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸"""
    query = request.args.get('q', '').strip()
    if not query:
        return jsonify({'error': 'ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.'}), 400
    
    # ì•ˆì „í•œ ê²€ìƒ‰ì–´ ì²˜ë¦¬
    safe_query = re.sub(r'[^\w\sê°€-í£]', '', query)
    if not safe_query:
        return jsonify({'error': 'ìœ íš¨í•œ ê²€ìƒ‰ì–´ê°€ ì•„ë‹™ë‹ˆë‹¤.'}), 400
    
    # YouTube ê²€ìƒ‰ URL ìƒì„±
    youtube_url = f"https://www.youtube.com/results?search_query={safe_query.replace(' ', '+')}"
    
    return jsonify({
        'search_url': youtube_url,
        'query': safe_query,
        'timestamp': datetime.now().isoformat()
    })

@app.route('/clear_history', methods=['POST'])
def clear_history():
    """ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”"""
    global conversation_history
    conversation_history = []
    return jsonify({
        'message': 'ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.',
        'timestamp': datetime.now().isoformat()
    })

@app.route('/conversation_stats')
def conversation_stats():
    """ëŒ€í™” í†µê³„ ë°˜í™˜"""
    total_messages = len(conversation_history)
    if total_messages == 0:
        return jsonify({
            'total_messages': 0,
            'memory_topics': {},
            'last_conversation': None
        })
    
    # ë©”ëª¨ë¦¬ ì£¼ì œ í†µê³„
    all_keywords = {}
    for conv in conversation_history:
        keywords = conv.get('memory_keywords', {})
        for category, words in keywords.items():
            if category not in all_keywords:
                all_keywords[category] = {}
            for word in words:
                all_keywords[category][word] = all_keywords[category].get(word, 0) + 1
    
    return jsonify({
        'total_messages': total_messages,
        'memory_topics': all_keywords,
        'last_conversation': conversation_history[-1]['timestamp'] if conversation_history else None
    })

@app.route('/health')
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    return jsonify({
        'status': 'healthy',
        'model_ready': model is not None,
        'conversation_count': len(conversation_history),
        'timestamp': datetime.now().isoformat()
    })

@app.errorhandler(404)
def not_found(error):
    return render_template('index.html'), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'}), 500

if __name__ == '__main__':
    print("ğŸš€ íšŒìƒì¹˜ë£Œ AI ì•„ë°”íƒ€ ì„œë²„ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    print(f"ğŸ“Š ì„¤ì •: ìµœëŒ€ íˆìŠ¤í† ë¦¬ {CONFIG['MAX_HISTORY']}ê°œ, ìµœëŒ€ ë¬¸ì¥ {CONFIG['RESPONSE_MAX_SENTENCES']}ê°œ")
    
    debug_mode = os.getenv('FLASK_DEBUG', 'False').lower() == 'true'
    app.run(
        debug=debug_mode, 
        host='0.0.0.0', 
        port=5000,
        threaded=True
    )
